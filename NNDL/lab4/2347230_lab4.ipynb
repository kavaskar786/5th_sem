{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4\n",
    "### kavaskar\n",
    "### 2347230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Data Preparation\n",
    "def load_data():\n",
    "    # Load Kuzushiji-MNIST dataset\n",
    "    (ds_train, ds_test), ds_info = tfds.load(\n",
    "        'kmnist',\n",
    "        split=['train', 'test'],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "    )\n",
    "    \n",
    "    def preprocess(image, label):\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        return tf.reshape(image, [-1]), label\n",
    "\n",
    "    # Apply preprocessing and convert to numpy arrays\n",
    "    ds_train = ds_train.map(preprocess).batch(ds_info.splits['train'].num_examples)\n",
    "    ds_test = ds_test.map(preprocess).batch(ds_info.splits['test'].num_examples)\n",
    "\n",
    "    X_train, y_train = next(iter(ds_train))\n",
    "    X_test, y_test = next(iter(ds_test))\n",
    "\n",
    "    return (X_train.numpy(), y_train.numpy()), (X_test.numpy(), y_test.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RBFNetwork:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.centers = None\n",
    "        self.weights = np.random.randn(hidden_dim, output_dim)\n",
    "    \n",
    "    def gaussian(self, x, c):\n",
    "        return np.exp(-np.linalg.norm(x - c, axis=1)**2 / (2 * (self.sigma**2)))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # RBF layer\n",
    "        G = np.zeros((X.shape[0], self.hidden_dim))\n",
    "        for i, center in enumerate(self.centers):\n",
    "            G[:, i] = self.gaussian(X, center)\n",
    "        \n",
    "        # Output layer\n",
    "        output = np.dot(G, self.weights)\n",
    "        return self.softmax(output)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    def train(self, X, y, learning_rate, epochs):\n",
    "        # Use K-means to determine RBF centers\n",
    "        kmeans = KMeans(n_clusters=self.hidden_dim)\n",
    "        kmeans.fit(X)\n",
    "        self.centers = kmeans.cluster_centers_\n",
    "        \n",
    "        # Compute sigma (width of Gaussian)\n",
    "        distances = np.zeros((self.hidden_dim, self.hidden_dim))\n",
    "        for i in range(self.hidden_dim):\n",
    "            for j in range(self.hidden_dim):\n",
    "                distances[i, j] = np.linalg.norm(self.centers[i] - self.centers[j])\n",
    "        self.sigma = np.mean(distances) / np.sqrt(2 * self.hidden_dim)\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            # Forward pass\n",
    "            output = self.forward(X)\n",
    "            \n",
    "            # Backward pass (gradient descent)\n",
    "            error = output - np.eye(self.output_dim)[y]\n",
    "            gradient = np.dot(self.gaussian(X, self.centers).T, error)\n",
    "            self.weights -= learning_rate * gradient\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss = -np.sum(np.eye(self.output_dim)[y] * np.log(output)) / X.shape[0]\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return np.argmax(output, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Training\n",
    "def train_model(X_train, y_train):\n",
    "    model = RBFNetwork(input_dim=784, hidden_dim=100, output_dim=10)\n",
    "    model.train(X_train, y_train, learning_rate=0.01, epochs=100)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Evaluation\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    return accuracy, conf_matrix\n",
    "\n",
    "def visualize_results(accuracy, conf_matrix):\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Analysis\n",
    "def analyze_rbf_units(X_train, y_train, X_test, y_test, rbf_units):\n",
    "    accuracies = []\n",
    "    for units in rbf_units:\n",
    "        model = RBFNetwork(input_dim=784, hidden_dim=units, output_dim=10)\n",
    "        model.train(X_train, y_train, learning_rate=0.01, epochs=100)\n",
    "        accuracy, _ = evaluate_model(model, X_test, y_test)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(rbf_units, accuracies, marker='o')\n",
    "    plt.title('RBF Units vs Accuracy')\n",
    "    plt.xlabel('Number of RBF Units')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kavas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (60000,784) (100,784) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m (X_train, y_train), (X_test, y_test) \u001b[38;5;241m=\u001b[39m load_data()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m accuracy, conf_matrix \u001b[38;5;241m=\u001b[39m evaluate_model(model, X_test, y_test)\n",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(X_train, y_train)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(X_train, y_train):\n\u001b[0;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m RBFNetwork(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m784\u001b[39m, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "Cell \u001b[1;32mIn[5], line 47\u001b[0m, in \u001b[0;36mRBFNetwork.train\u001b[1;34m(self, X, y, learning_rate, epochs)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Backward pass (gradient descent)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m error \u001b[38;5;241m=\u001b[39m output \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim)[y]\n\u001b[1;32m---> 47\u001b[0m gradient \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcenters\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT, error)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m gradient\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m, in \u001b[0;36mRBFNetwork.gaussian\u001b[1;34m(self, x, c)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgaussian\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, c):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)))\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (60000,784) (100,784) "
     ]
    }
   ],
   "source": [
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    (X_train, y_train), (X_test, y_test) = load_data()\n",
    "\n",
    "    # Train the model\n",
    "    model = train_model(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy, conf_matrix = evaluate_model(model, X_test, y_test)\n",
    "    visualize_results(accuracy, conf_matrix)\n",
    "\n",
    "    # Analyze the effect of RBF units\n",
    "    rbf_units = [50, 100, 150, 200, 250]\n",
    "    analyze_rbf_units(X_train, y_train, X_test, y_test, rbf_units)\n",
    "\n",
    "    print(\"Strengths of RBF Network for this dataset:\")\n",
    "    print(\"1. Can capture non-linear relationships in the data.\")\n",
    "    print(\"2. Faster training compared to some other neural network architectures.\")\n",
    "    print(\"3. Good at handling localized features, which may be important for character recognition.\")\n",
    "\n",
    "    print(\"\\nLimitations of RBF Network for this dataset:\")\n",
    "    print(\"1. Performance heavily depends on the choice of centers and number of RBF units.\")\n",
    "    print(\"2. May require more memory as the number of RBF units increases.\")\n",
    "    print(\"3. Can be sensitive to the scale of the input features.\")\n",
    "\n",
    "    print(\"\\nEffect of number of RBF units:\")\n",
    "    print(\"Increasing the number of RBF units generally improves the model's ability to capture complex patterns,\")\n",
    "    print(\"but it also increases computational cost and the risk of overfitting. There's usually an optimal\")\n",
    "    print(\"number of units beyond which performance plateaus or degrades. The analyze_rbf_units function\")\n",
    "    print(\"helps visualize this trade-off.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
